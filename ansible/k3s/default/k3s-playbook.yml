---
- hosts: "localhost"
  connection: local
  gather_facts: false
  vars_files:
    - vars.yaml
  vars:
    # tf integration (optional).
    terraform_workspace: "{{ lookup('env', 'TF_WORKSPACE') | default('') }}"
    use_terraform: "{{ terraform_workspace != '' and terraform_workspace is defined }}"
    terraform_state_file: "{{ (lookup('env', 'TERRAFORM_NODE_SOURCE') | default('tofu/aws/modules/cluster_nodes')) + '/terraform.tfstate.d/' + terraform_workspace + '/terraform.tfstate' if use_terraform else '' }}"

    kube_api_host: "{{ lookup('cloud.terraform.tf_output', 'kube_api_host', state_file=terraform_state_file) if use_terraform else lookup('env', 'KUBE_API_HOST') }}"
    ansible_ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
  tasks:

    - name: Wait for SSH on node
      wait_for:
        host: "{{ hostvars[item]['ansible_host'] }}"
        port: 22
        timeout: 300
        state: started
      loop: "{{ groups['all'] }}"

- hosts: "all"
  become: true
  gather_facts: false
  tasks:
    - name: Gather minimal OS facts
      setup:
        gather_subset:
          - '!all'
          - '!min'
          - distribution
          - os_family
      when: ansible_os_family is not defined

 
    - name: Disable NetworkManager cloud setup services
      systemd:
        name: "{{ item }}"
        state: stopped
        enabled: no
      loop:
        - nm-cloud-setup.service
        - nm-cloud-setup.timer
      failed_when: false
      when: 
        - ansible_os_family == "RedHat"
        - ansible_distribution_major_version|int >= 8

    - name: Create NetworkManager config for CNI interfaces
      copy:
        content: |
          [keyfile]
          unmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:flannel*
        dest: /etc/NetworkManager/conf.d/99-cni.conf
        mode: '0644'
      when: ansible_os_family == "RedHat"

    - name: Restart NetworkManager
      systemd:
        name: NetworkManager
        state: restarted
      when: ansible_os_family == "RedHat"

- hosts: "master"
  become: true
  gather_facts: false
  vars_files:
    - vars.yaml
  vars:
    # tf integration (optional).
    terraform_workspace: "{{ lookup('env', 'TF_WORKSPACE') | default('') }}"
    use_terraform: "{{ terraform_workspace != '' and terraform_workspace is defined }}"
    terraform_state_file: "{{ (lookup('env', 'TERRAFORM_NODE_SOURCE') | default('tofu/aws/modules/cluster_nodes')) + '/terraform.tfstate.d/' + terraform_workspace + '/terraform.tfstate' if use_terraform else '' }}"

    kube_api_host: "{{ lookup('cloud.terraform.tf_output', 'kube_api_host', state_file=terraform_state_file) if use_terraform else lookup('env', 'KUBE_API_HOST') }}"
    fqdn: "{{ lookup('cloud.terraform.tf_output', 'fqdn', state_file=terraform_state_file) if use_terraform else (lookup('env', 'FQDN') | default('')) }}"
    node_token_file: "/tmp/node_token.txt" # Local file to store the token
    ansible_ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
  tasks:
    - name: Create K3s server directories on master
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - /var/lib/rancher/k3s/server
        - /var/lib/rancher/k3s/server/manifests
        - /var/lib/rancher/k3s/server/logs

      when: '"cp" in ansible_role or "etcd" in ansible_role'
    - name: Read hardening files content
      slurp:
        src: "./{{ item }}"
      register: hardening_files
      loop:
        - policy.yaml
        - audit.yaml
        - cluster-level-pss.yaml
        - ingresspolicy.yaml
        - cis_master_config.yaml
      delegate_to: localhost
      run_once: true

    - name: Install K3s on initial cluster node
      include_role:
        name: k3s_install
      vars:
        k3s_node_type: cluster-init
        kubernetes_version: "{{ kubernetes_version }}"
        kube_api_host: "{{ kube_api_host }}"
        fqdn: "{{ fqdn }}"
        k3s_node_roles: "{{ ansible_role }}"
        public_ip: "{{ ansible_host }}"
        server_flags: "{{ server_flags | default('') }}"
        k3s_channel: "{{ channel | default('') }}"
        # Pass hardening file contents as variables
        policy_yaml_content: "{{ (hardening_files.results | selectattr('item', 'equalto', 'policy.yaml') | first).content | b64decode }}"
        audit_yaml_content: "{{ (hardening_files.results | selectattr('item', 'equalto', 'audit.yaml') | first).content | b64decode }}"
        cluster_level_pss_yaml_content: "{{ (hardening_files.results | selectattr('item', 'equalto', 'cluster-level-pss.yaml') | first).content | b64decode }}"
        ingresspolicy_yaml_content: "{{ (hardening_files.results | selectattr('item', 'equalto', 'ingresspolicy.yaml') | first).content | b64decode }}"
        cis_master_config_yaml_content: "{{ (hardening_files.results | selectattr('item', 'equalto', 'cis_master_config.yaml') | first).content | b64decode }}"
      when: inventory_hostname == "master"


    - name: Get node-token from master
      raw: cat /var/lib/rancher/k3s/server/node-token
      register: node_token_output

    - name: Save node_token to local file
      delegate_to: localhost
      run_once: true
      become: no
      shell: echo "{{ node_token_output.stdout }}" > "{{ node_token_file }}"

    - name: Read file contents into a variable
      raw: cat /etc/rancher/k3s/k3s.yaml
      register: file_contents

    - name: Save file contents locally
      delegate_to: localhost
      run_once: true
      become: no
      shell: echo "{{ file_contents.stdout }}" > "{{ kubeconfig_file }}"

- hosts: "all"
  become: true
  gather_facts: false
  vars_files:
    - vars.yaml
  vars:
    # tf integration (optional).
    terraform_workspace: "{{ lookup('env', 'TF_WORKSPACE') | default('') }}"
    use_terraform: "{{ terraform_workspace != '' and terraform_workspace is defined }}"
    terraform_state_file: "{{ (lookup('env', 'TERRAFORM_NODE_SOURCE') | default('tofu/aws/modules/cluster_nodes')) + '/terraform.tfstate.d/' + terraform_workspace + '/terraform.tfstate' if use_terraform else '' }}"

    kube_api_host: "{{ lookup('cloud.terraform.tf_output', 'kube_api_host', state_file=terraform_state_file) if use_terraform else lookup('env', 'KUBE_API_HOST') }}"
    fqdn: "{{ lookup('cloud.terraform.tf_output', 'fqdn', state_file=terraform_state_file) if use_terraform else (lookup('env', 'FQDN') | default('')) }}"
    server_host: "{{ server_host_override | default((groups['all'] | selectattr('terraform_facts.output_nodes.value[inventory_hostname].is_server', 'defined') | selectattr('terraform_facts.output_nodes.value[inventory_hostname].is_server', 'true') | map('inventory_hostname') | list)[0] if use_terraform else groups['master'][0]) }}"
    node_token_file: "/tmp/node_token.txt" # Local file to store the token
    ansible_ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
  tasks:
    - name: Read node_token from local file
      delegate_to: localhost
      run_once: true
      become: false
      slurp:
        src: "{{ node_token_file }}"
      register: node_token_file_content

    - name: Set node_token fact from file content
      set_fact:
        node_token: "{{ node_token_file_content.content | b64decode | trim }}"
      run_once: true
      delegate_to: localhost

    - name: Create K3s server directories on server nodes
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
      loop:
        - /var/lib/rancher/k3s/server
        - /var/lib/rancher/k3s/server/manifests
        - /var/lib/rancher/k3s/server/logs
      when: '"cp" in ansible_role or "etcd" in ansible_role'

    - name: Read hardening files content for server nodes
      slurp:
        src: "./{{ item }}"
      register: hardening_files_servers
      loop:
        - policy.yaml
        - audit.yaml
        - cluster-level-pss.yaml
        - ingresspolicy.yaml
        - cis_master_config.yaml
      delegate_to: localhost
      become: no
      run_once: true
      when: '"cp" in ansible_role or "etcd" in ansible_role'

    - name: Install K3s on server nodes
      include_role:
        name: k3s_install
      vars:
        k3s_node_type: server
        kubernetes_version: "{{ kubernetes_version }}"
        kube_api_host: "{{ kube_api_host }}"
        fqdn: "{{ fqdn }}"
        k3s_token: "{{ node_token }}"
        k3s_node_roles: "{{ ansible_role }}"
        public_ip: "{{ ansible_host }}"
        server_flags: "{{ server_flags | default('') }}"
        k3s_channel: "{{ channel | default('v1') }}"
        # Pass hardening file contents as variables
        policy_yaml_content: "{{ (hardening_files_servers.results | selectattr('item', 'equalto', 'policy.yaml') | first).content | b64decode }}"
        audit_yaml_content: "{{ (hardening_files_servers.results | selectattr('item', 'equalto', 'audit.yaml') | first).content | b64decode }}"
        cluster_level_pss_yaml_content: "{{ (hardening_files_servers.results | selectattr('item', 'equalto', 'cluster-level-pss.yaml') | first).content | b64decode }}"
        ingresspolicy_yaml_content: "{{ (hardening_files_servers.results | selectattr('item', 'equalto', 'ingresspolicy.yaml') | first).content | b64decode }}"
        cis_master_config_yaml_content: "{{ (hardening_files_servers.results | selectattr('item', 'equalto', 'cis_master_config.yaml') | first).content | b64decode }}"
      when: 
        - inventory_hostname != "master"
        - '"cp" in ansible_role or "etcd" in ansible_role'
        
    - name: Install K3s on agent nodes
      include_role:
        name: k3s_install
      vars:
        k3s_node_type: agent
        kubernetes_version: "{{ kubernetes_version }}"
        kube_api_host: "{{ kube_api_host }}"
        fqdn: "{{ fqdn }}"
        k3s_token: "{{ node_token }}"
        public_ip: "{{ ansible_host }}"
        worker_flags: "{{ worker_flags | default('') }}"
        k3s_channel: "{{ channel | default('v1') }}"
      when: ansible_role == "worker"

- hosts: localhost
  connection: local
  gather_facts: false
  vars_files:
    - vars.yaml
  tasks:
    - name: Wait until all K3s system pods are Running or Succeeded
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig_file }}"
        api_version: v1
        kind: Pod
        namespace: kube-system
      register: k3s_pods_check
      until: >
        k3s_pods_check.resources is defined and
        (k3s_pods_check.resources | rejectattr('status.phase', 'in', ['Running', 'Succeeded']) | list | length == 0)
      retries: 5
      delay: 60
